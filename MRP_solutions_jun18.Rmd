---
title: "Non-probability-based Surveys in Practice"
author: "Matthew Salganik and Janet Xu ^[based on the activity from SICSS 2017 created by Matthew Salganik and Yo-Yo Chen]"
date: "June 21, 2018"
output: pdf_document
---

# Outline:
-Step 0: Loading data and packages

  - Approach 1: Simple Means 
      
      - 1.1) Calculate means
      - 1.2) Plot estimated means against benchmarks
      - 1.3) Plot distribution of estimation-benchmark differences 

  - Approach 2) Means with post-stratification (i.e. weighted means)
      
      - 2.1) Calculate group means, group weights, and weighted means
          
              -  2.1.1) Dealing with missing groups: imputing with sample means
          
      - 2.2) Plot estimated means against benchmarks
      - 2.3) Plot distribution of estimation-benchmark differences 
      
  - Approach 3) Model-based estimation with post-stratification
      
      - 3.1) Predict group means with simple regression model; combine with group weights to create weighted means
      - 3.2) Plot estimated means against benchmarks
      - 3.3) Plot distribution of estimation-benchmark differences 

  - Approach 4) Multilevel-Model-based estimation with post-stratification (MRP)
    
      - 4.1) Predict group means with multi-level regression model; combine with group weights to create weighted means
      - 4.2) Plot estimated means against benchmarks
      - 4.3) Plot distribution of estimation-benchmark differences 
    
- Explore errors across questions and methods 

\newpage

# Step 0: Load packages and data

```{r, message = F, warning = F, echo = T }
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

# load packages
library(tidyverse)
library(lme4)
# library(rstanarm) load if using Bayesian estimation for multi-level model
## note that Bayesian estimation is more computationally intensive/takes longer

# comment out line below and set your working directory
setwd("~/Dropbox/SICSS/mturk_survey_2018/data/") #jx working directory

# load cleaned data file
data <- read.csv("cleaned_mturk_jun18_data.csv")

## not using education, political ideology/party, or 
## political knowledge attention check, so drop  
## (you can use if you want!)
data <- data %>% select(-attention1, -educ, -ideology, -party1, -party2)

# load external information -- in this case, population info
census <- read.csv("cleaned_acs16.csv", stringsAsFactors = F)

# load pew benchmarks
pew <- read_csv("pew_Apr17_benchmarks.csv", col_names = c("qid", "pew_estimate")) 
```

\newpage

# Approach 1): Simple Means 

This approach doesn't use any post-stratification. We just take the mean of the sample.

## 1.1: Calculate Means

```{r}
# take the mean of survey responses in mturk data
mturk_means <- data %>% select(-sex, -race, -age_cat, -region) %>%
  summarise_all(funs(mean), na.rm = T) %>%
  gather(qid, mean) 

head(mturk_means)
```

## 1.2: Plot estimated means against benchmarks

**Tip**: You will be making this type of plot each time you generate a new set of estimates, so it would be helpful to write a function for this.

```{r}

# merge mturk cell-based weighed estimates with benchmark
mean_est <- inner_join(pew, mturk_means, by = c("qid"))
head(mean_est)

# make function for plot
plot_comparison <- function(est_table, method, caption){
  graph <-  ggplot(est_table, 
                   aes(x = pew_estimate, y = method)) + 
  geom_point() + 
  labs(x = "Estimates from Pew", y = caption) +
  scale_x_continuous(limits = c(0,1)) + 
  scale_y_continuous(limits = c(0,1)) + 
  geom_abline(intercept = 0, slope = 1, linetype = "dotted") + 
  coord_fixed()
  return(graph)
}  

#plot
plot_comparison(est_table = mean_est, 
                method = mean_est$mean, 
                caption = "Non-weighted estimates from MTurk")
```

## 1.3: Plot distribution of estimation-benchmark differences 

**Tip**: You will also be making this type of plot each time you generate a new set of estimates, so it would be helpful to write a function for this as well.

```{r}
#calculate difference
mean_est$diff <- abs(mean_est$mean - mean_est$pew_estimate)

# function for plotting difference
plot_diff <- function(est_table){
  diff_graph <- ggplot(est_table, aes(x = diff)) + 
  geom_histogram(aes(y = (..count..)/sum(..count..)), binwidth = .025, 
                 colour = "black", fill = "white") + 
  theme_bw() + 
  geom_vline(aes(xintercept = median(diff)), linetype = "longdash") + 
  labs(x = "absolute difference", y = "density") + 
  scale_y_continuous(limits = c(0, 0.35))
  return(diff_graph)
}

#plot
plot_diff(mean_est)
```

\newpage

# Approach 2: Means with post-stratification (i.e. weighted means)

## 2.1: Calculate group means, group weights, and weighted means

Group weights can be calculated as $\frac{N_{h}}{N}$. They should sum to 1. You will use these for the model-based approaches as well. 

*Note*: If a group is missing from the sample (e.g. 50-64 year old black women in the midwest), their answers will automatically be treated as "zero" when computing weighted means. As a result, some answer responses may be underestimated. One way to deal with this is to impute the missing values with the sample average for that variable (aka the simple means we calculated in the previous step). 

```{r}
# get total census population
N <- sum(census$POP)

# create weight by grouping by demographic categories,
# then summing each cell and dividing by total pop
population_counts <- census %>% 
  group_by(sex, age_cat, race, region) %>% 
  summarise(group_weight = sum(POP)/N)

# check that weights sum to one
if (sum(population_counts$group_weight) != 1) {
  print("weights don't sum to one")
}

# view
head(population_counts)
tail(population_counts)

# calculate means for each question response
sample_counts <- data %>% 
  group_by(sex, age_cat, race, region) %>% 
  summarise_all(funs(mean), na.rm = T)

# preview -- scroll for more columns
head(sample_counts)

# check how many groups are missing
if (nrow(sample_counts) < nrow(population_counts)) {
  print("GROUPS MISSING:")
  print(nrow(population_counts) - nrow(sample_counts))
}
# 73 of the 160 categories are missing

# merge population_counts with sample counts -- left join to retain all groups
# in population, even if not in sample
cell_based <- left_join(population_counts, 
            sample_counts, 
            by = c("sex", "age_cat", "race", "region"))

# reshape wide to long
cell_based_long <- cell_based %>% gather(qid, mean, 
                                         -c(sex, age_cat, race, region, group_weight),
                                         na.rm = F) 

head(cell_based_long)

# multiply the group means and group weights in the cell_long_2 dataframe 
# and call this weighted mean
cell_based_long <- mutate(cell_based_long, weighted_mean = group_weight*mean)

# then sum the group-specific weighted means, grouping by question
mturk_cell_est <- cell_based_long %>% 
  group_by(qid) %>%
  summarise(mturk_cell_estimate = sum(weighted_mean, na.rm = T))

head(mturk_cell_est)

```

### 2.1.1: Dealing with missing groups: imputing with means

```{r}
# isolate missing groups:
missing_groups <- cell_based_long %>% filter(is.na(mean))

# merge sample means vector created in 1.1 (mturk_means) with this new dataframe
missing_groups_imputed <- inner_join(missing_groups, mturk_means, by = c("qid")) %>%
  select(-mean.x, -weighted_mean) %>%
  rename(mean = mean.y)

# now merge back with all non-missing groups (stored in cell_based_long)
cell_based_long_imputed <- right_join(missing_groups_imputed, cell_based_long,
                                     by = c("sex", "age_cat", "race", "region",
                                            "group_weight" , "qid")) %>%
                            mutate(mean = ifelse(is.na(mean.x), mean.y, mean.x)) %>%
                            select(-mean.x, -mean.y, -weighted_mean) %>%
# now recalculate weighted means  
                            mutate(weighted_mean_imputed = group_weight*mean)

# then sum the group-specific weighted means, grouping by question
cell_est_imputed <- cell_based_long_imputed %>% 
  group_by(qid) %>%
  summarise(mturk_cell_estimate = sum(weighted_mean_imputed, na.rm = T))

head(cell_est_imputed)

```

## 2.2: Plot estimated means against benchmarks

```{r}
################################## WITH NO IMPUTATION ###################################
# merge mturk cell-based weighed estimates with benchmark
cell_based_est <- inner_join(pew, mturk_cell_est, by = c("qid"))
head(cell_based_est)

#plot
plot_comparison(est_table = cell_based_est, 
                method = cell_based_est$mturk_cell_estimate, 
                caption = "Cell-based weighted estimates from MTurk")

################################## WITH IMPUTATION ######################################
# merge mturk cell-based weighed estimates with benchmark
cell_est_imputed <- inner_join(pew, cell_est_imputed, by = c("qid"))
head(cell_est_imputed)

#plot
plot_comparison(est_table = cell_est_imputed, 
                method = cell_est_imputed$mturk_cell_estimate, 
                caption = "Cell-based weighted estimates from MTurk (with data imputation)")
```


## 2.3: Plot distribution of estimation-benchmark differences

```{r}
#################################### WITH NO IMPUTATION #################################
#calculate difference
cell_based_est$diff <- abs(cell_based_est$mturk_cell_estimate - cell_based_est$pew_estimate)

#plot
plot_diff(cell_based_est)

#################################### IMPUTATION #######################################

#calculate difference
cell_est_imputed$diff <- abs(cell_est_imputed$mturk_cell_estimate - cell_est_imputed$pew_estimate)

#plot
plot_diff(cell_est_imputed)
```

\newpage

# Approach 3: Model-based estimation with post-stratification

## 3.1: Estimate means with simple regression model

```{r}
# for this, we will need convert everything into factors
data_factor <- data %>% mutate_all(funs(as.factor))

# Now we will regress each survey answer on demographic characteristics and
# use those model parameters to generate predicted probabilities for each group
# loop through each survey answer and store each vector of pred.probs
# in a 160 x 35 matrix 

# but first, write a warning function for later to make sure 
# that all estimates are 0 to 1 inclusive
prob_range_warning <- function(predictions){
  if (any(predictions < 0)) {
    warning("some predictions less than zero")
    } 
  if (any(predictions > 1)) {
    warning("some predictions more than one")
    } 
}

# create a character vector of the 35 question names
# these question names can be found in the column names of the data
relevant_questions <- colnames(data)[!colnames(data) %in% c("sex", "age_cat", "race", "region")]

# create container
model_predictions <- as.data.frame(matrix(nrow = nrow(population_counts), 
                                          ncol = length(relevant_questions), NA))
colnames(model_predictions) <- relevant_questions
# loop through
for (i in relevant_questions) {
  # pick outcome
  outcome <- data_factor[ , i]
  # fit model
  model <- glm(outcome ~ sex + age_cat + region + race, 
             data = data_factor,
             family = binomial(link = "logit"))
  # create predicted probabilities
  reg_predicted_values <- predict(model, newdata = population_counts, type = "response")
  # check for errors
  prob_range_warning(reg_predicted_values)
  # store in container
  model_predictions[ , i] <- reg_predicted_values
}

# bind demographic categories to predictions
model_wide <- bind_cols(population_counts, model_predictions)
head(model_wide)

# reshape wide to long
model_long <- model_wide %>% gather(qid, predicted_value, 
                                         -c(sex, age_cat, race, region, group_weight),
                                         na.rm = F) 
head(model_long)

# weigh and sum by qid
model_est <- model_long %>%
  mutate(weighed_prediction = group_weight*predicted_value) %>%
  group_by(qid) %>%
  summarise(model_prediction = sum(weighed_prediction, na.rm = T)) 

head(model_est)

# merge with pew benchmarks
pew_model_est <- inner_join(pew, model_est, by = c("qid"))
```

## 3.2: Plot estimated means against benchmarks

```{r}
plot_comparison(est_table = pew_model_est,
                method = pew_model_est$model_prediction,
                caption = "Model-based predicted values") 
```

## 3.3: Plot distribution of estimation-benchmark differences 

```{r}
#calculate difference
pew_model_est$diff <- abs(pew_model_est$model_prediction - pew_model_est$pew_estimate)

#plot
plot_diff(pew_model_est)
```

\newpage

# Approach 4: Multilevel-Model-based estimation with post-stratification (MRP)

## 4.1: Estimate means with multi-level regression model

```{r}
# create container
mrp_model_predictions <- as.data.frame(matrix(nrow = nrow(population_counts), 
                                          ncol = length(relevant_questions), NA))
colnames(mrp_model_predictions) <- relevant_questions

# loop through model fitting and prediction
for (i in relevant_questions) {
  outcome <- data_factor[ , i]
  # fit -- note that this is using default priors
  # nested the model name in "capture.out" to silently fit
  output <- capture.output(multilevel_model <- 
                          glmer(outcome ~ sex + (1|age_cat) + (1|race) + 
                          (1|region), data = data, family = binomial(link = "logit")))
  # predict
  mrp_predictions <- predict(multilevel_model, 
                                       newdata = population_counts, type = "response")
  # errors?
  prob_range_warning(mrp_predictions)
  # feed into dataframe
  mrp_model_predictions[ , i] <- mrp_predictions
}

##################### Bayesian version with STAN #################################################

#for (i in relevant_questions) {
  #outcome <- data_factor[ , i]
  ## fit -- note that this is using default priors
  ## nested the model name in "capture.out" to silently fit
  #output <- capture.output(multilevel_model <- 
                         # stan_glmer(outcome ~ sex + (1|age_cat) + (1|race) + 
                         # (1|region), data = data, family = binomial(link = "logit")))
  ## predict
  #mrp_predictions <- posterior_linpred(multilevel_model, 
                                      # newdata = population_counts, type = "response")
  #mrp_predictions_invlog <- exp(mrp_predictions)/(1 + exp(mrp_predictions))
  #mrp_pred2 <- unname(apply(mrp_predictions_invlog, 2, mean))
  ## errors?
  #prob_range_warning(mrp_pred2)
  ## feed into dataframe
  #mrp_model_predictions[ , i] <- mrp_pred2
#}

# bind to demographic categories and group weights
mrp_wide <- bind_cols(population_counts, mrp_model_predictions)
head(mrp_wide)

# reshape wide to long
mrp_long <- mrp_wide %>% gather(qid, predicted_value, 
                                         -c(sex, age_cat, race, region, group_weight),
                                         na.rm = F) 
head(mrp_long)

# weigh, sum by qid, match with pew
mrp_est <- mrp_long %>%
  mutate(mrp_weighted_prediction = group_weight*predicted_value) %>%
  group_by(qid) %>%
  summarise(mrp_prediction = sum(mrp_weighted_prediction, na.rm = T)) 

head(mrp_est)

# merge with pew benchmarks
pew_mrp_est <- inner_join(pew, mrp_est, by = c("qid"))
```

## 4.2: Plot estimated means against benchmarks

```{r}
plot_comparison(est_table = pew_mrp_est,
                method = pew_mrp_est$mrp_prediction,
                caption = "MRP predicted values")
```

## 4.3: Plot distribution of estimation-benchmark differences

```{r}
#calculate difference
pew_mrp_est$diff <- abs(pew_mrp_est$mrp_prediction - pew_mrp_est$pew_estimate)

#plot
plot_diff(pew_mrp_est)
```

\newpage

# Compare distribution of differences across methods and questions:

Which questions worked well and which didn't? Which methods worked well for which questions?

```{r}
# put all differences into one table 
all_diff <- inner_join(mean_est, cell_based_est, by = "qid") %>%
           select(qid, diff_mean = diff.x, diff_cell = diff.y) %>%
              inner_join(., cell_est_imputed, by = "qid") %>%
              select(qid, diff_mean, diff_cell, diff_cell_imputed = diff) %>%
                  inner_join(., pew_model_est, by = "qid") %>%
                  select(qid, diff_mean, diff_cell, diff_cell_imputed, diff_model = diff) %>%
                    inner_join(., pew_mrp_est, by = "qid") %>%
                    select(qid, diff_mean, diff_cell, diff_cell_imputed, diff_model, diff_mrp = diff)

# summarize
summary(all_diff)

# calculate MSE 
colMeans(apply(all_diff[ ,-1], 2, FUN = function(x){x^2}))

# calculate average difference across all methods for each question
all_diff$avg_diff <- apply(all_diff[ ,-1], 1, FUN = mean)


```